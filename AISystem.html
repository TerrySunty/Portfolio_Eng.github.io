<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="Mark Otto, Jacob Thornton, and Bootstrap contributors">
    <meta name="generator" content="Jekyll v4.1.1">
    <title>Game AI System Based on Q-Learning</title>

    <link rel="canonical" href="https://getbootstrap.com/docs/4.5/examples/album/">

    <!-- Bootstrap core CSS -->
    <link href="./assets/dist/css/bootstrap.min.css" rel="stylesheet">

    <style>
        .bd-placeholder-img {
            font-size: 1.125rem;
            text-anchor: middle;
            -webkit-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            user-select: none;
        }

        @media (min-width: 768px) {
            .bd-placeholder-img-lg {
                font-size: 3.5rem;
            }
        }
    </style>
    <!-- Custom styles for this template -->
    <link href="album.css" rel="stylesheet">
</head>
<body background="./img/Qbackground.png">
<header>
    <div class="collapse bg-dark" id="navbarHeader">
        <div class="container">
            <div class="row">
                <div class="col-sm-8 col-md-7 py-4">
                    <h4 class="text-white">About</h4>
                    <p class="text-muted">This website is for my own portfolio.</p>
                </div>
                <div class="col-sm-4 offset-md-1 py-4">
                    <h4 class="text-white">Contact Me</h4>
                    <ul class="list-unstyled">
                        <a href="https://space.bilibili.com/130853098/channel/detail?cid=148180" class="text-white">Related videos on Bilibili.com</a>
                        <li><h6 style="color: #ffffff">Email: terrysunty@qq.com</h6></li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
    <div class="navbar navbar-dark bg-dark shadow-sm">
        <div class="container d-flex justify-content-between">
            <a href="./index.html" class="navbar-brand d-flex align-items-center">
                <strong>TerrySunty | AI System</strong>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarHeader" aria-controls="navbarHeader" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
        </div>
    </div>
</header>

<main role="main">

    <section class="jumbotron text-center">
        <div class="container">
            <h2>Game AI System Based on Q-Learning Algorithm</h2>
            <p class="lead text-muted">My graduation thesis project<br/>Obtained outstanding graduation thesis of CQUT in 2020
            </p>

        </div>
    </section>


    <div class="album py-5 bg-transparent" align="center">
        <div class="album py-5 bg-dark" align="center" style="width:50%">
            <h4 style="color: white">Brief Introduction</h4>
            <p style="color: white;text-align: left;margin-right: 10px;margin-left: 10px">
                Nowadays, in many games, there is a game AI system to interact with players, but most of them has logic bugs. For example, In NBA2K Series,
                NPC players will do double-team when the player gets points to a certain value, for example 40 points. It is reasonable for NPCs to do act of
                double-team when player plays an important role in attacking, but it is unreasonable for NPCs to do act of double-team when player keeps passing the ball to teammates to get points.
                NPCs in NBA2K won’t stop doubling the player although the player keeps passing the ball, and there are also many game
                AI systems similar with NBA 2K’s game AI system. Such kinds of game AI with low intelligence may cause players to lose interests in the game.
                Therefore, the traditional game AI system needs to introduce powerful Artificial Intelligence algorithms to improve the intelligence of game AI and meet players’ needs.
                To improve game AI’s intelligence, this project improves the game AI system based on UE4's behavior tree by using a Q-Learning algorithm and semi-supervised learning method.<br/>
                After many training tests and verification, the behavioral decision-making ability of game AI has been shown improved to a certain extent.
                Game AI can change the mechanism of behavior decision
                according to the different players’ operation level. It also balances the gameplay and the intelligence of game AI to a certain extent.
            </p>
        </div>
        <div class="album py-5 bg-dark" align="center" style="width: 50%;margin-top: 30px">
            <h4 style="color: white">Demo Video for part of results</h4><br>
            <iframe src="//player.bilibili.com/player.html?aid=668523546&bvid=BV1Ma4y1Y72a&cid=255014433&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="width: 600px; height: 450px"> </iframe>
            <br/>
            <img src="./img/RTableEng.png" alt="报酬函数表" width="70%" height="50%" style="margin-top: 50px"><br/>
            <small style="color:white">The figure above is the reward function table used in the system, which is R1 in R function.<br/> States in Q-table are referred to the R table.</small><br>
            <p style="color:white;text-align: left;margin-left: 10px;margin-right: 10px">The demo video begins with two simulations of game NPC (non-player character) facing a player with higher combat ability, NPC's decision will be made according to first Q-table:<br/>
            </p>
            <img src="./img/Strong.png" alt="Strong Player Q table" width="70%" height="100%" style="margin-top: 50px"><br>
            <small style="color: white">Q-Table when NPC meets strong player</small><br><br>
            <ol style="color: white;text-align: left;margin-left: 10px;margin-right: 10px">
                <li>When NPC is equipped with a weapon，NPC sees the player and the death prop(which can make the player die immediately) at the same time, NPC has two choices——fight with the player/pick up the prop，NPC chooses to avoid fighting and pick up the prop, to get better result.</li>
                <li>When NPC is not equipped with a weapon, NPC sees both the player and the weapon, at this point NPC has two options -- flee/pick up weapons and then fight the player, and it chooses to flee for better result.
                    Later，the video shows that under default behavior tree (not improved)，under the same conditions, since the priority of picking up weapon is higher, the NPC chooses to pick up the weapon.</li>
            </ol>
            <p style="color:white;text-align: left;margin-left: 10px;margin-right: 10px">Then，the video shows two simulations when the NPC facing a player with weaker combat ability,NPC's decision will be made according to second Q-table::</p><br/>
            <img src="./img/Weak.png" alt="Weak Player Q table" width="70%" height="100%" style="margin-top: 50px"><br>
            <small style="color: white">Q-Table when NPC meets weak player</small><br><br>
            <ol style="color:white;text-align: left;margin-left: 10px;margin-right: 10px">
                <li>When NPC is equipped with a weapon，NPC sees the player and the death prop, NPC chooses to fight with the player for better result.</li>
                <li>When NPC is not equipped with a weapon, NPC sees both the player and the weapon, NPC chooses to pick up the weapon and then fight with the player.</li>
            </ol>

        </div>

        <div class="album py-5 bg-dark" align="center" style="width: 50%; margin-top: 30px">
            <h4 style="color: white">Brief Introduction of Q-Learning</h4>
            <img src="./img/QLFormula.png" alt="Q函数公式" width="70%" height="100%" style="margin-top: 50px"><br>
            <small style="color: white">The figure above shows Q function in Q-Learning algorithm.</small>
            <br/>
            <img src="./img/RFunction.png" alt="R函数公式" width="50%" height="50%" style="margin-top: 50px"><br/>
            <small style="color:white">The figure above shows R function( reward function)</small>
            <br/>
            <br/>
            <h4 style="color: red;margin-top: 50px">An simple example.</h4>
            <img src="./img/QExample.png" alt="举例说明" width="85%" height="50%" style="margin-top: 20px"><br/>
            <br/>
            <p style="color: white;text-align: left;margin-left: 10px;margin-right: 10px">
                Assume that we are in doing homework state, and we have been never tried playing games while doing homework before, so we have two options now:
                <br/>1, Continue doing homework;<br/> 2, Playing games. <br/><br/>
                Since we have never been punished before, so we choose to play games. When parents come back, they find us are playing games without finishing homework.
                Then parents punish us, we get penalty value(negative Q value) at this time. We put this experience in memory, and realize that the behavior of playing games without finishing homework
                will bring negative result,(set the Q value of playing games under doing homework state as negative value).
                Next time, under doing homework state and facing the two options, we will choose the action with better result, continue doing homework to get better result.

            </p>
            <p style="color: white;text-align: left;margin-left: 10px;margin-right: 10px">
                Similar with the example, at the beginning, NPC knows nothing about game environment（all state-action value are 0 in Q Table).
                NPC gains rewards or penalties by constantly interacting with the game environment and using the Q function to
                update Q values of different actions under different states.
                As Q value converges to a certain value, many steps of learning are needed to get it. Therefore,
                some researches artificially construct a state-action reward function table (R-value table) by experience, which provides certain prior knowledge for agents.
            </p>
        </div>

    </div>


</main>

<footer class="text-muted">
    <div class="container">
        <p class="float-right">
            <a href="index.html" >Back to homepage</a><br/>
            <a href="#">Back to top</a>
        </p>
        <p>This website is my personal portfolio, no reproduction without permission</p>
    </div>
</footer>
<script src="./jquery-3.5.1.slim.min.js" ></script>
<script>window.jQuery || document.write('<script src="./assets/js/vendor/jquery.slim.min.js"><\/script>')</script>
<script src="./assets/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
